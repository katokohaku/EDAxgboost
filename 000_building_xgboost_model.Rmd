---
author: "Satoshi Kato"
title: "building xgboost model"
date: "`r format(Sys.time(), '%Y/%m/%d')`"
output:
  html_document:
    fig_caption: yes
    pandoc_args:
      - --from
      - markdown+autolink_bare_uris+tex_math_single_backslash-implicit_figures
    keep_md: yes
    toc: yes
  word_document:
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_knit$set(progress = TRUE, 
                     verbose  = TRUE, 
                     root.dir = ".")

knitr::opts_chunk$set(collapse = FALSE, 
                      comment = "", 
                      message = TRUE, 
                      warning = FALSE, 
                      include = TRUE,
                      echo    = TRUE)

set.seed(1)
```

```{r install.requirements, eval = FALSE}
install.packages("breakDown",   dependencies = TRUE)
install.packages("fastDummies", dependencies = TRUE)
install.packages("xgboost",     dependencies = TRUE)
install.packages("tidyverse",   dependencies = TRUE)
install.packages("AUC",         dependencies = TRUE)

install.packages("caret", dependencies = FALSE)

```

```{r require.packages, message=FALSE}
require(fastDummies)
require(xgboost)
require(tidyverse)
require(AUC)
require(caret)

```

# Data preparation

```{r data.prep}
data(HR_data, package = "breakDown")
HR_data %>% str

HR.dummy <- HR_data %>% 
  dummy_cols(select_columns = c("sales", "salary"), remove_first_dummy = FALSE) %>% 
  select(-sales, -salary, -sales_management, -salary_high)

train.i <- sample(NROW(HR.dummy), NROW(HR.dummy) / 3)
test.i  <- setdiff(1:NROW(HR.dummy), train.i)

train.df     <- HR.dummy[train.i, ] 
train.matrix <- train.df %>% select(-left) %>% as.matrix()
# train.matrix %>% str
train.label  <- HR.dummy[train.i, ]$left
train.xgb.DMatrix <- xgb.DMatrix(train.matrix, label = train.label)
table(train.label)

test.df     <- HR.dummy[test.i, ] 
test.matrix <- test.df %>% select(-left) %>% as.matrix()
# test.matrix %>% str
test.label  <- HR.dummy[test.i, ]$left
test.xgb.DMatrix <- xgb.DMatrix(test.matrix, label = test.label)
table(test.label)

```

# parameter settings for XGBoost

see. https://xgboost.readthedocs.io/en/latest/parameter.html

```{r parameter.settings}
params <- list(
  booster      = "gbtree", # MUST be set booster = "gbtree" to build explainer
  objective    = "binary:logistic",
  eval_metric  = "auc",    # instead of "logloss", "error" and "aucpr"
  max_depth = 5,
  colsample_bytree= 0.8,
  subsample = 0.8,
  min_child_weight = 3,
  eta   = 0.05,
  alpha = 0.25,
  gamma = 0
) 

```

```{r xgb.cv}
cv <- xgb.cv(params  = params, 
             verbose = 1,
             data    = train.xgb.DMatrix,
             nrounds = 200,
             nfold   = 5,
             early_stopping_rounds = 10)

print(cv, verbose=TRUE)

```

```{r}
model.xgb <- xgb.train(params  = params, 
                       verbose = 1,
                       data    = train.xgb.DMatrix,
                       nrounds = cv$best_iteration)

```

# Save data and model

```{r save.object}
res <- list(
  data = list(
    original = HR.dummy,
    train = list(
      dummy.data.frame = train.df,
      matrix = train.matrix,
      label  = train.label
    ),
    test = list(
      dummy.data.frame = test.df,
      matrix = test.matrix,
      label  = test.label
    )
  ),
  model = list(
    param.set = params,
    cv = cv,
    xgb = model.xgb
  )
)
 
saveRDS(res, file = "./middle/data_and_model.Rds")
xgb.DMatrix.save(train.xgb.DMatrix, fname = "./middle/train.xgbDMatrix")
xgb.DMatrix.save(test.xgb.DMatrix,  fname = "./middle/test.xgbDMatrix")

```


